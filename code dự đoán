LINK T·∫¢I model YOLO: https://drive.google.com/file/d/1JEridz0WfOPmWWA6Q4PczaQd4_41YNHT/view?usp=sharing


LINK T·∫¢I model CNN: https://drive.google.com/file/d/14ZnRULy6y1a4LyDObOe3CyeaEVBhmL3A/view?usp=sharing
-Th∆∞ vi·ªán c·∫ßn t·∫£i
pip install ultralytics tensorflow pillow opencv-python numpy

-CODE D·ª∞ ƒêO√ÅN
import tkinter as tk
from tkinter import filedialog
from PIL import Image, ImageTk
import cv2
from ultralytics import YOLO
import numpy as np
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.image import img_to_array
import threading
import os
import datetime

# Danh s√°ch m√≥n ƒÉn v√† gi√°
food_prices = {
    "Ca hu kho": 15000,
    "Canh cai": 8000,
    "Canh chua": 10000,
    "Com trang": 5000,
    "Dau hu sot ca": 12000,
    "Ga chien": 20000,
    "Rau muong xao": 8000,
    "Thit kho": 15000,
    "Thit kho trung": 20000,
    "Trung chien": 7000
}

# Load m√¥ h√¨nh YOLO v√† CNN
yolo_model = YOLO("yolov8n.pt")
cnn_model = load_model("CNNAI.h5")

# T·∫°o th∆∞ m·ª•c l∆∞u ·∫£nh n·∫øu ch∆∞a c√≥
os.makedirs("captured_images", exist_ok=True)

def detect_and_classify(image_path):
    image = cv2.imread(image_path)
    results = yolo_model(image)[0]

    preds = []
    for box in results.boxes:
        x1, y1, x2, y2 = map(int, box.xyxy[0])
        crop = image[y1:y2, x1:x2]
        crop_resized = cv2.resize(crop, (128, 128))
        crop_resized = crop_resized.astype("float32") / 255.0
        crop_resized = img_to_array(crop_resized)
        crop_resized = np.expand_dims(crop_resized, axis=0)

        pred = cnn_model.predict(crop_resized, verbose=0)
        class_idx = np.argmax(pred)
        class_name = list(food_prices.keys())[class_idx]
        preds.append(class_name)

        cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)
        cv2.putText(image, class_name, (x1, y1 - 10),
                    cv2.FONT_HERSHEY_SIMPLEX, 0.6, (0, 255, 0), 2)

    return image, preds

def open_image():
    file_path = filedialog.askopenfilename()
    if file_path:
        show_result(file_path)

def show_result(image_path):
    result_text.delete(1.0, tk.END)
    image_label.config(image=None)
    image_label.image = None

    img_annotated, preds = detect_and_classify(image_path)
    img_display = cv2.cvtColor(img_annotated, cv2.COLOR_BGR2RGB)
    img_pil = Image.fromarray(img_display)
    img_pil = img_pil.resize((400, 300)) # Gi·∫£m k√≠ch th∆∞·ªõc hi·ªÉn th·ªã
    img_tk = ImageTk.PhotoImage(img_pil)
    image_label.config(image=img_tk)
    image_label.image = img_tk

    if not preds:
        result_text.insert(tk.END, "‚ùå Kh√¥ng nh·∫≠n di·ªán ƒë∆∞·ª£c m√≥n ƒÉn.")
        return

    food_counts = {}
    for food in preds:
        food_counts[food] = food_counts.get(food, 0) + 1

    total = 0
    for food, count in food_counts.items():
        price = food_prices.get(food, 0)
        result_text.insert(tk.END, f"‚Ä¢ {food} x{count} = {price * count:,} ƒë\n")
        total += price * count

    result_text.insert(tk.END, f"\nüëâ T·ªïng ti·ªÅn: {total:,} ƒë")

    # ‚ûï Ghi log m√≥n ƒÉn
    with open("log.txt", "a", encoding="utf-8") as f:
        timestamp = datetime.datetime.now().strftime("%Y-%m-%d %H:%M:%S")
        for food in preds:
            f.write(f"{timestamp},{food}\n")

cap = None
webcam_running = False

def start_webcam():
    global cap, webcam_running
    if webcam_running:
        return
    cap = cv2.VideoCapture(0)
    if not cap.isOpened():
        result_text.delete(1.0, tk.END)
        result_text.insert(tk.END, "‚ùå Kh√¥ng th·ªÉ m·ªü webcam.")
        return

    webcam_running = True
    result_text.delete(1.0, tk.END)
    result_text.insert(tk.END, "üì∑ Webcam ƒëang ho·∫°t ƒë·ªông. Nh·∫•n 'Ch·ª•p ·∫£nh' ƒë·ªÉ ch·ª•p.")

    def video_loop():
        while webcam_running:
            ret, frame = cap.read()
            if not ret:
                break
            frame_rgb = cv2.cvtColor(frame, cv2.COLOR_BGR2RGB)
            img = Image.fromarray(frame_rgb)
            img = img.resize((400, 300)) # Gi·∫£m k√≠ch th∆∞·ªõc hi·ªÉn th·ªã
            imgtk = ImageTk.PhotoImage(img)
            image_label.imgtk = imgtk
            image_label.configure(image=imgtk)

    threading.Thread(target=video_loop, daemon=True).start()

def capture_webcam_image():
    global cap, webcam_running
    if not webcam_running or cap is None:
        result_text.delete(1.0, tk.END)
        result_text.insert(tk.END, "‚ùå Webcam ch∆∞a ƒë∆∞·ª£c b·∫≠t.")
        return
    ret, frame = cap.read()
    if not ret:
        result_text.delete(1.0, tk.END)
        result_text.insert(tk.END, "‚ùå Kh√¥ng th·ªÉ l·∫•y h√¨nh ·∫£nh t·ª´ webcam.")
        return

    timestamp = datetime.datetime.now().strftime("%Y%m%d_%H%M%S")
    img_path = f"captured_images/captured_{timestamp}.jpg"
    cv2.imwrite(img_path, frame)
    result_text.insert(tk.END, f"üíæ ƒê√£ l∆∞u ·∫£nh: {img_path}\n")
    show_result(img_path)

def stop_webcam():
    global cap, webcam_running
    webcam_running = False
    if cap is not None:
        cap.release()
        cap = None
    image_label.config(image="")
    image_label.image = None
    result_text.delete(1.0, tk.END)
    result_text.insert(tk.END, "‚ùå Webcam ƒë√£ d·ª´ng.")

# ‚ûï Th·ªëng k√™ m√≥n ƒÉn ph·ªï bi·∫øn trong ng√†y
def show_today_stats():
    result_text.delete(1.0, tk.END)
    if not os.path.exists("log.txt"):
        result_text.insert(tk.END, "‚ö†Ô∏è Ch∆∞a c√≥ d·ªØ li·ªáu th·ªëng k√™.")
        return

    today = datetime.datetime.now().strftime("%Y-%m-%d")
    food_counter = {}

    with open("log.txt", "r", encoding="utf-8") as f:
        for line in f:
            if line.startswith(today):
                parts = line.strip().split(",")
                if len(parts) == 2:
                    _, food = parts
                    food_counter[food] = food_counter.get(food, 0) + 1

    if not food_counter:
        result_text.insert(tk.END, "üìÖ H√¥m nay ch∆∞a c√≥ m√≥n ƒÉn n√†o ƒë∆∞·ª£c nh·∫≠n di·ªán.")
        return

    sorted_foods = sorted(food_counter.items(), key=lambda x: x[1], reverse=True)
    result_text.insert(tk.END, f"üìä Th·ªëng k√™ m√≥n ƒÉn ph·ªï bi·∫øn ({today}):\n\n")
    for food, count in sorted_foods:
        result_text.insert(tk.END, f"‚Ä¢ {food}: {count} ph·∫ßn\n")

    most_common = sorted_foods[0]
    result_text.insert(tk.END, f"\nüèÜ M√≥n ƒÉn ph·ªï bi·∫øn nh·∫•t h√¥m nay: {most_common[0]} ({most_common[1]} ph·∫ßn)")

# ======= GUI =======
root = tk.Tk()
root.title("üß† Nh·∫≠n di·ªán m√≥n ƒÉn canteen (YOLO + Keras)")
root.geometry("1200x600") # TƒÉng chi·ªÅu r·ªông c·ª≠a s·ªï
root.configure(bg="#f0f4f8")

def on_enter(e):
    e.widget['background'] = '#5dade2'

def on_leave(e):
    e.widget['background'] = '#3498db'

title = tk.Label(root, text="üç± H·ªá th·ªëng nh·∫≠n di·ªán m√≥n ƒÉn canteen", font=("Segoe UI", 24, "bold"),
                    bg="#f0f4f8", fg="#34495e")
title.grid(row=0, column=0, columnspan=3, pady=25)

# --- C·ªôt b√™n tr√°i (Input) ---
input_frame = tk.Frame(root, bg="#f0f4f8")
input_frame.grid(row=1, column=0, padx=20, sticky="n")

btn_open = tk.Button(input_frame, text="üìÇ Ch·ªçn ·∫£nh t·ª´ m√°y", bg="#27ae60", fg="white",
                     activebackground="#2ecc71", font=("Segoe UI", 14, "bold"),
                     padx=20, pady=10, bd=0, relief="ridge", command=open_image)
btn_open.pack(pady=5, fill="x")

btn_camera_start = tk.Button(input_frame, text="‚ñ∂Ô∏è B·∫≠t Webcam", bg="#3498db", fg="white",
                             activebackground="#5dade2", font=("Segoe UI", 14, "bold"),
                             padx=20, pady=10, bd=0, relief="ridge", command=start_webcam)
btn_camera_start.pack(pady=5, fill="x")
btn_camera_start.bind("<Enter>", on_enter)
btn_camera_start.bind("<Leave>", on_leave)

btn_camera_capture = tk.Button(input_frame, text="üì∏ Ch·ª•p ·∫£nh", bg="#2ecc71", fg="white",
                                 activebackground="#58d68d", font=("Segoe UI", 14, "bold"),
                                 padx=20, pady=10, bd=0, relief="ridge", command=capture_webcam_image)
btn_camera_capture.pack(pady=5, fill="x")

btn_camera_stop = tk.Button(input_frame, text="‚èπÔ∏è T·∫Øt Webcam", bg="#e74c3c", fg="white",
                              activebackground="#ec7063", font=("Segoe UI", 14, "bold"),
                              padx=20, pady=10, bd=0, relief="ridge", command=stop_webcam)
btn_camera_stop.pack(pady=5, fill="x")

btn_stats = tk.Button(input_frame, text="üìä Th·ªëng k√™ h√¥m nay", bg="#f39c12", fg="white",
                      activebackground="#f4d03f", font=("Segoe UI", 12, "bold"),
                      padx=20, pady=10, bd=0, relief="ridge", command=show_today_stats)
btn_stats.pack(pady=10, fill="x")

# --- C·ªôt ·ªü gi·ªØa (Camera/·∫¢nh) ---
image_frame = tk.Frame(root, bg="white", relief="groove", bd=3)
image_frame.grid(row=1, column=1, padx=20, pady=10)

image_label = tk.Label(image_frame, bg="white", width=400, height=300, relief="sunken", bd=2)
image_label.pack()

# --- C·ªôt b√™n ph·∫£i (Output) ---
output_frame = tk.Frame(root, bg="#f0f4f8")
output_frame.grid(row=1, column=2, padx=20, sticky="n")

result_label = tk.Label(output_frame, text="üìù K·∫øt qu·∫£ nh·∫≠n di·ªán:", font=("Segoe UI", 16, "bold"),
                        bg="#f0f4f8", fg="#34495e")
result_label.pack(pady=(0, 5), anchor="w")

result_container = tk.Frame(output_frame, bg="white", relief="ridge", bd=2)
result_container.pack(pady=5, fill="both", expand=True)

scrollbar = tk.Scrollbar(result_container)
scrollbar.pack(side="right", fill="y")

result_text = tk.Text(result_container, height=10, font=("Segoe UI", 14), wrap="word",
                        yscrollcommand=scrollbar.set, bg="white", fg="#2c3e50")
result_text.pack(fill="both", padx=10, pady=10, expand=True)
scrollbar.config(command=result_text.yview)

root.grid_columnconfigure(1, weight=1) # Cho c·ªôt gi·ªØa (·∫£nh) c√≥ th·ªÉ gi√£n n·ªü

root.mainloop()

