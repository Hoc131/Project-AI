LINK T·∫¢I model YOLO: https://drive.google.com/file/d/1JEridz0WfOPmWWA6Q4PczaQd4_41YNHT/view?usp=sharing


LINK T·∫¢I model CNN: https://drive.google.com/file/d/14ZnRULy6y1a4LyDObOe3CyeaEVBhmL3A/view?usp=sharing
-Th∆∞ vi·ªán c·∫ßn t·∫£i
!pip install ultralytics tensorflow gradio opencv-python
!pip install gradio

-CODE D·ª∞ ƒêO√ÅN
import gradio as gr
import cv2
import numpy as np
from ultralytics import YOLO
from tensorflow.keras.models import load_model
from tensorflow.keras.preprocessing.image import img_to_array
from PIL import Image

yolo_model = YOLO("/content/drive/MyDrive/yolov8n.pt") #model yolo

# Keras .h5 ƒë·ªÉ ph√¢n lo·∫°i m√≥n ƒÉn
classifier_model = load_model("/content/drive/MyDrive/cantin_model.h5") # model CNN

# Danh s√°ch nh√£n t∆∞∆°ng ·ª©ng v·ªõi m√¥ h√¨nh classifier
class_labels = [
    "Ca hu kho", "Canh cai", "Canh chua", "Com trang", "Dau hu sot ca",
    "Ga chien", "Rau muong xao", "Thit kho", "Thit kho trung", "Trung chien"
]

# B·∫£ng gi√° m√≥n ƒÉn
food_prices = {
    "Ca hu kho": 10000,
    "Canh cai": 8000,
    "Canh chua": 8000,
    "Com trang": 5000,
    "Dau hu sot ca": 7000,
    "Ga chien": 12000,
    "Rau muong xao": 6000,
    "Thit kho": 12000,
    "Thit kho trung": 14000,
    "Trung chien": 7000
}

def preprocess_crop(crop_img):
    img = cv2.resize(crop_img, (128, 128))
    img = img.astype("float32") / 255.0
    img = np.expand_dims(img, axis=0)
    return img

def detect_and_classify(image):
    results = yolo_model(image)
    detections = results[0].boxes.data.cpu().numpy()

    predicted_classes = []
    total_price = 0

    for det in detections:
        x1, y1, x2, y2, score, class_id = det
        if score < 0.3:
            continue

        crop = image[int(y1):int(y2), int(x1):int(x2)]
        if crop.size == 0:
            continue

        # Ti·ªÅn x·ª≠ l√Ω v√† ph√¢n lo·∫°i b·∫±ng CNN
        input_img = preprocess_crop(crop)
        preds = classifier_model.predict(input_img)
        predicted_index = np.argmax(preds[0])
        predicted_label = class_labels[predicted_index]

        predicted_classes.append(predicted_label)
        total_price += food_prices.get(predicted_label, 0)

    if not predicted_classes:
        return image, "<span style='color:red'>Kh√¥ng ph√°t hi·ªán ƒë∆∞·ª£c m√≥n ƒÉn!</span>", "0 ƒë"

    result_html = "".join([
        f"<li>{label}: {food_prices[label]:,} ƒë</li>" for label in predicted_classes
    ])
    return image, f"<ul>{result_html}</ul>", f"{total_price:,} ƒë"

# === Giao di·ªán Gradio ===
header = """
<div style="text-align:center; padding: 20px;">
    <h1 style="color:#2E8B57">üç± Nh·∫≠n Di·ªán M√≥n ƒÇn & T√≠nh Ti·ªÅn</h1>
    <p>T·∫£i ·∫£nh m√¢m c∆°m l√™n ƒë·ªÉ ph√°t hi·ªán v√† t√≠nh gi√° c√°c m√≥n ƒÉn</p>
</div>
"""

with gr.Blocks(theme=gr.themes.Soft()) as demo:
    gr.HTML(header)
    with gr.Row():
        with gr.Column():
            image_input = gr.Image(type="numpy", label="üì∑ ·∫¢nh m√¢m c∆°m")
            btn = gr.Button("üîç Nh·∫≠n di·ªán & t√≠nh ti·ªÅn")
        with gr.Column():
            image_output = gr.Image(type="numpy", label="·∫¢nh k·∫øt qu·∫£")
            food_list = gr.HTML(label="üçΩÔ∏è Danh s√°ch m√≥n ƒÉn")
            total_cost = gr.Textbox(label="üí∞ T·ªïng ti·ªÅn")

    btn.click(fn=detect_and_classify, inputs=image_input, outputs=[image_output, food_list, total_cost])
# Ch·∫°y ·ª©ng d·ª•ng
demo.launch()
